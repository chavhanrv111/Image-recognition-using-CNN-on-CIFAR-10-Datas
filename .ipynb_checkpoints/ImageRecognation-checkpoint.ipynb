{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2be9a5",
   "metadata": {},
   "source": [
    "##Image recognition using CNN on CIFAR-10 Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014899a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f30c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(X_train, y_train), (X_test, y_test)= cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635d2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "\n",
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255.0\n",
    "X_test/=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdb7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "\n",
    "y_train= to_categorical(y_train,10)\n",
    "y_test= to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a0fdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3), padding='same', input_shape=(32,32,3), activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1da7ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1180160   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3fe48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 307s 195ms/step - loss: 1.5367 - accuracy: 0.4376 - val_loss: 1.2035 - val_accuracy: 0.5702\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 308s 197ms/step - loss: 1.1315 - accuracy: 0.5983 - val_loss: 0.9377 - val_accuracy: 0.6687\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 307s 196ms/step - loss: 0.9774 - accuracy: 0.6559 - val_loss: 0.8485 - val_accuracy: 0.7007\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 310s 198ms/step - loss: 0.8873 - accuracy: 0.6874 - val_loss: 0.7882 - val_accuracy: 0.7227\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 307s 197ms/step - loss: 0.8255 - accuracy: 0.7129 - val_loss: 0.7850 - val_accuracy: 0.7263\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 317s 203ms/step - loss: 0.7800 - accuracy: 0.7246 - val_loss: 0.7392 - val_accuracy: 0.7473\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 311s 199ms/step - loss: 0.7417 - accuracy: 0.7384 - val_loss: 0.7287 - val_accuracy: 0.7492\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 184s 117ms/step - loss: 0.7129 - accuracy: 0.7509 - val_loss: 0.7275 - val_accuracy: 0.7466\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 177s 113ms/step - loss: 0.6909 - accuracy: 0.7548 - val_loss: 0.7094 - val_accuracy: 0.7548\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 174s 111ms/step - loss: 0.6651 - accuracy: 0.7669 - val_loss: 0.6642 - val_accuracy: 0.7702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2246596dbd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74a356c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4383"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the neural network architecture\n",
    "\n",
    "model_structure= model.to_json()\n",
    "f=Path(\"model_structure.json\")\n",
    "f.write_text(model_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "046589aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained neural etwork weights\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a73a5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the images\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a799bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 Dataset class labels\n",
    "\n",
    "class_labels=[\n",
    "    \"Planes\",\n",
    "    \"Car\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Boat\",\n",
    "    \"Truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e308c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file that contains the model structure\n",
    "\n",
    "f=Path(\"model_structure.json\")\n",
    "model_structure= f.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d2b6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the keras model object from the json data\n",
    "model= model_from_json(model_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65a4d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-load the model training weights\n",
    "model.load_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd177004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x224999bde10>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgZ0lEQVR4nO2deZDc5Xnnv8+vr+nuOXpmNJJGBxKSOCRkzCEwLAQILnttKjF4K0XhOC6SZa1UYtfatWylKG+V7VSFBHtjHFcOJ/JCmez6wsYH68I2MrFN8NoIcQkhAQIdaEZzaI6eo+/j2T+6tRHs+/3NoJnpkXmfT5VKPe933l+//Zvf07/p9zvP84iqwjCMtz/Bci/AMIzWYMFuGJ5gwW4YnmDBbhieYMFuGJ5gwW4YnhBdyGQReR+ALwGIAPgfqnpP2Pf39kZ0w/qIU6tW+by6MKFO54RZipGAv8cVa3yeECkRZQsEYrFufjzEqFavjXFN+Y+tDvdaVBN0ThCJUy0SssZaLU81CdzzItH2MzpeJNLFn0v4z7NWLTvHg0jInNos1erK1zg1PUO1SJRfq1VyHbcl3LECADEinRisY3LSHTFnHOwiEgHw9wDeA2AAwFMi8rCqHmBzNqyP4Be7Vzu1iUke7QUSS/Wi+wcJANVakWrdqQ6qvTheolqSBPu5K/gPZWXfrVSLyyqq5afv41ppJdXK4g7cUm0DnZPuOIdqHVhDtens01RLtK9zP1f31XTO7DQ/XlfnTVSLJvnPc2r8iHM8FXINTM8+TrWZ2j6q/Xj3T6nW2c2v1bGC+01i27n8jXFVp/uau+3WKTpnIb/GXwngVVU9rKplAN8EcPMCjmcYxhKykGBfC+D4aV8PNMcMwzgLWfINOhHZKSJ7RWTv2Dj/3GIYxtKykGAfBLD+tK/XNcfegKruUtUdqrpjRa9t/hvGcrGQ6HsKwHkicq6IxAHcBuDhxVmWYRiLzRnvxqtqVUQ+DuAnaFhv96vqi2FzcqU69rw67dR64nz3XLp6nOMvZ7kN0t7GX9pUidtrL4+61wcAW4gVor1pOker3DKqJy6kmkS2Ua0jcynVSlX37jOmCnQOiiNUCtLcMcj0/C7Vom3uc6Ihn+S0zu89QaRCtUohR7V4lFhvdb47vu8Qd5D3HOLnMV3jjlK5xu3NZIf7eiwWuDP0atltbZaq/NpekM+uqo8AeGQhxzAMozXYh2jD8AQLdsPwBAt2w/AEC3bD8AQLdsPwhAXtxr9VytUaBrNua2v9hn46b3DanYV0Isftuq6AWx2Hx3h20myWSiiuddsdxSJfx2zlSaplAp5kkoteTrWU8HmJwG151du5JVMlmXIAUNMM1ZJpntGHIOkeRo1OWZH5d1Sr1vn6T07xP+9Yk3mXc7xe5xZaezv3B6+71P26AODAbn7MVCd/3bV4yjmeTvMEq/0D7mu4HJI9and2w/AEC3bD8AQLdsPwBAt2w/AEC3bD8ISW7sZHIwF6Oty7mYkUT3Roq7h3i/M5vkO7uou/tHQmpOVVle9Mdyfcu/HJFJ9TyZPEFABBipcd6k1cRrWqnqBarehOnujs4McrVyeppjX3TnFjIVwqB1nneCwIqckX8N1nUe6urOq6gmql0qhz/OmX/5bOyYMnNonw5KvUBr5TPzbOE6wy3e7X3d7G6/9tybjXmIhwR8Du7IbhCRbshuEJFuyG4QkW7IbhCRbshuEJFuyG4Qkttd7qqsiV3RZbOSTR4Zxut81w/fncjpmamaBadze3f0YmeNulAmlpVCmFtHECt5M0wtdRrfPXVgupdZaIuWveBRGe3BELSXaphhSNq+hJqhXy7vMfSfLjBcLPRyAh9qZyC7Mu7iSqizfeSeccPPZRquUTfB3JDE92Gcry62CGaD8f4glbPeK2+Sq8tJ7d2Q3DFyzYDcMTLNgNwxMs2A3DEyzYDcMTLNgNwxMWZL2JyFEAMwBqAKqquiPs+8uqOEHa7qya4Flv71zrtia2reE2SG52NdWOTHLrqquTZy4FVbe1Eov10jmd6e1Uq5SOUq0Gd8srAMiVuCUzVn/FOb66l58r1C+gUljbJYTYYZGou05eLj9A58RT/HJMBfy+FBeu5eWAc7wW6aNzyskQazPJLdFCnltvQY1rr2fdzzd2mNuUfT3u7MZShc9ZDJ/9t1WVm9OGYZwV2K/xhuEJCw12BfCoiDwtIjsXY0GGYSwNC/01/lpVHRSRlQB2i8hLqvr46d/QfBPYCQDdKxf4bIZhnDELurOr6mDz/1EA3wNwpeN7dqnqDlXdkeatyg3DWGLOONhFJC0iHaceA3gvgP2LtTDDMBaXhfwavwrA96Rhv0QBfF1Vfxw2oS0SxXmkZdBD+3kG1VTEbYdd08ezzeIRbp8cmsxSTdp4sUFWyq8W7aBzggTPdqrH+OmvVng7rEzv9VQrF4k1FGKTVVPHqFYq7qNarcozFdsia53jQcCtoTp4UcYp5ZrW+DFrxPI6nv0LOqer/RyqTRR5Wlk0zm3Kbb1cezHrtgHzHYN8HRPu11Wr8oKYZxzsqnoYwDvPdL5hGK3FrDfD8AQLdsPwBAt2w/AEC3bD8AQLdsPwhJYWnIxFI+hf0enUrg3a6Lwjg+6igZOTvK/VDedfSLV4rEi1bJW//xVq7kyjNXl3PzEASLatolomcSPVahH3eQKAQo6vsa7uc1Wr8Wy+aHQD1dIJrg0VfkK1Il52jgc1fu7TaZ6JNlzg51grvLhoqs1teWVSF9M5xfI41do7uc031sbnFcr8+s5n3D+blUleSPP1l4gFKPz82p3dMDzBgt0wPMGC3TA8wYLdMDzBgt0wPKHF7Z8ERdLWqD+VoPP6N69zjh95/QidE63xcnjr1/KkkLGXefJBIpFxjo9Pn0/nXLbpH6iWzVIJQcBrlkFDJsZTzuFoJWSXVvllUBGuret+P9XGZ59yP5fwBKVIwHfj48Lr7u0deZRqfUn3bny8kqNzDk7xnf91PTxP+0QtQ7XZUb5TP1KddI73pvl1mu9wXx/1gCcn2Z3dMDzBgt0wPMGC3TA8wYLdMDzBgt0wPMGC3TA8oaXWm0AQJU85QFrgAEC0zW2TnHcBrxVWiLxGtT17jlNty3reyikVcds/l2/+Mzrn4LM/p1rvuv+vGO//Q0Jqxs0O8/X3rXUnrmiE1+tjddoAoD7hTqwBgGI6Q7Vo7R3u48mv6RwoT9YplHmNwpOFEaqdyLutyOvXcAttY4LbwM+ecNtkADB4gttrNbIOAEDMndBVy/BWU71l9/ojUf7zsju7YXiCBbtheIIFu2F4ggW7YXiCBbtheIIFu2F4wpzWm4jcD+B3AIyq6vbmWA+AbwHYCOAogFtVlXsSTep1QTHvthMkxe2fGqnfNTHBM7niXQNUu3HbJqoVCtzWyqQ+6Ryv5nh72smRx6mWXHER1bqS/H345Amemdfbu8I5Lkle006VZ0pVZvhzxercLk32ZJzjh4+foHN6+niLpEKOr2NVG2+xlZt126XjvJsUclXe4qlQ5ueqI87XMTDB6+RtvcZ9/QyXeCunCjn3ioVlvX0VwPveNHYXgMdU9TwAjzW/NgzjLGbOYG/2W3/z29LNAB5oPn4AwC2LuyzDMBabM/3MvkpVh5qPh9Ho6GoYxlnMgjfotPGBj35QEJGdIrJXRPZOTfLPeIZhLC1nGuwjItIPAM3/aR0fVd2lqjtUdUdXd0v/FN8wjNM402B/GMDtzce3A/jB4izHMIylYj7W2zcA3ABghYgMAPgMgHsAPCgidwA4BuDW+TxZqa44POu2V9K8qw429rvfk548yjN8jh7jFsTVW7gN1dnOM9E29vwH53h+9DCds27jFVSr1/mLvuKK36Laig5emHH3j7/nHBd1t64CgED4e3487bbyAODzd3+Banf//T3O8e2b3mzs/BtHhvdRrSPgGWCpGLe8xtWd7XfgFd46LB7nYdGTTFPtwBTPejvnPJ5NmUm5MxwHxvj1UZ5xr19rfM6cwa6qHyLSu+eaaxjG2YP9BZ1heIIFu2F4ggW7YXiCBbtheIIFu2F4Qkv/yiVXquH/HJlyah053stry2p31ltfwJcv3R1UK/FkOfR0/HuqHT+2xzkeq4zROUHqYqqVx3mvug///n+k2sWb3UUlAaAcuIsldoZkvQUBf8/XJC9U2bea21DDg684xyujWTontelcqlUK3JaLuy8pAMDKqPvaSW/kVlhduIU2fpJbdsEMv7Amc9z6TCbcxSNX8pqjmIyRgpPCe9jZnd0wPMGC3TA8wYLdMDzBgt0wPMGC3TA8wYLdMDyhpdZbUKshOZV1agVtp/OqJbfFc3VIr7d/2fci1Vb3X0c1FC/gUvYl53ihxqsXtkW4FsS4rXXHH7L8IyAZ5RlgELfF8/D3f0KnRIVn0W3fzrPe/tOdvMddPecusDiU433ZVqf6qVaa4MWQtvTwnCzmKuarvJ/bC4e+RbVEjJ/7i1ZlqFYc5X3sNsbcfeBmQjLYBl53l5CohRTEtDu7YXiCBbtheIIFu2F4ggW7YXiCBbtheEJLd+P7OjvxJ+9xJ5r84tCzdN4LJ9yJCRVeegwnCjwhoLfzdqpNjvCsikxXj/u5BobpnK6QZJGShhTeU94KKZfnbYGU7DLfffdf0jnjJ3kCRzTgCUr7Xnmer4O8tGQkpNVUSLJILMnbg3V28cSg2Qm3m5BOuXfAAWBlmicoZfUA1dIBL5We6nQnrgBAH97pHK8W+Draiu6YCJRnz9id3TA8wYLdMDzBgt0wPMGC3TA8wYLdMDzBgt0wPGE+7Z/uB/A7AEZVdXtz7LMAPgrgZPPbPqWqj8x1rHq9gkLxhFO7cetmOu/YsLvG269eov0kEQ3ctccAYPjIcaq1RfkpyRXd1kokwpMqyiVuGZXbeCJMUOAJNNkpd5IJAHT3uc/jBz5wC53znW9/n2ob16+j2sw0b7/V1eFO/Bh6nbfK6t28mmqdHdv5OvI/pFqx5L6fJZTXkmuLc9uzPlWm2myCe8H1Mv95Pn/gEFkIt4FPjruvq2p1YYkwXwXgatD1RVW9pPlvzkA3DGN5mTPYVfVxAPxWYhjGbwQL+cz+cRHZJyL3i0j3oq3IMIwl4UyD/csANgO4BMAQANq7V0R2isheEdk7meWfhQzDWFrOKNhVdURVa6paB/AVALSpuaruUtUdqrqjO8M3pAzDWFrOKNhF5PT6QR8EsH9xlmMYxlIxH+vtGwBuALBCRAYAfAbADSJyCQAFcBTAH8/nyWaKFfzswJBTu+ly+ssBzu13Z5sdGX2Gztl/gmdrHZ34KdXWrTyfauW4u1bbZNZtJwJAcgW3XKoTPHttVvmPJpHkra2yY5PO8cI032O96Hxue0pIltr48RALc4u7ntxIllte52bdaweA9iK3tQYnjlKtXnSn3xVjPHstVxykWoW0kwKAeJR/TB0d59fjySPua2T1Jr4VlieZj/U6z6ScM9hV1VX58L655hmGcXZhf0FnGJ5gwW4YnmDBbhieYMFuGJ5gwW4YntDSgpPVKjAx6X5/GZ04SOdFxF0ccCrPi+u9eJxbTe0pXtzyxpA2VJl299o7kzzrbWKY23Jj07xQ5YUXcgtweIBbXu0pd5ukSoXbQv39vO3S0DBf4/CxX1Ft44bbnOOX/dZKOkfH+Os61v5Lqs2UuJ23fuVG53g54K+rbYL/zCbH+XlMBLw1VDrB5w1F3AU/Dw+4sz0BoOs8dwHLyFPc4rM7u2F4ggW7YXiCBbtheIIFu2F4ggW7YXiCBbtheEJLrbd0MsC7trrtiXVruNUE0gNs/6EX6ZSUcBtEutZQ7V0f/M9U++pfubUgwvvKZbZwezAW55lcX//6P1Htqh38XP3osR85xx/b/RydkyOZYQBQmOZZe3/6+xtD5r3mHJ+oPkrn5LPc9lx1AbflNlf4OoKCu0hoUOXXRz3SS7X2BC8COTiRpdpUjF8HReLc1sv8+oiw3ncht2+7sxuGJ1iwG4YnWLAbhidYsBuGJ1iwG4YntHQ3vi2awoV9lzq13tp6Om8o665nmUjyemBXr7mYare//x6qzeR5e58P/dnfOMef/9WDdM7LL/Bkkf5ztlLtoW/sodr3f8iTQnpz7t3ntRl+foskEQMA4gGvCPw3n/9fVPv0l7Y5xw9nR+icrds6qTY1424nBQD93e5EKQCowL1rHS/zRKnpIk9amcrzc1WJ8HDKz/JafsUZ9zHTSe5OlKaIA1Tjzord2Q3DEyzYDcMTLNgNwxMs2A3DEyzYDcMTLNgNwxPm0/5pPYB/BrAKjXZPu1T1SyLSA+BbADai0QLqVlXl/XsAFOtlvJRzJzQMjvG6X796zl2frr2d2zG/e92fUq1cIUkEALTOk1rK5bRzvNLGLaN8NUu10eO87l5Ht/u5AGBgdJZqv3fl1c7xvoDbU+3Cz8c7LuJJIfvi3KI6/4LrneNP/mwvnZOcXUe1l375MtW2XvQS1zrcl6QEo3TOZIHbV8qdWSTAk2va49zC3HiO+56b6eDhWa+6befdsYXVoKsCuFNVtwG4CsDHRGQbgLsAPKaq5wF4rPm1YRhnKXMGu6oOqeozzcczAA4CWAvgZgAPNL/tAQC3LNEaDcNYBN7SZ3YR2QjgUgBPAlilqqdasg6j8Wu+YRhnKfMOdhFpB/AQgE+q6hsqGqiqovF53jVvp4jsFZG909mQDzyGYSwp8wp2EYmhEehfU9XvNodHRKS/qfcDcO54qOouVd2hqjs6M3wDwzCMpWXOYBcRQaMf+0FVvfc06WEAtzcf3w7gB4u/PMMwFov5ZL1dA+AjAF4QkeeaY58CcA+AB0XkDgDHANw614FmC0U88eKrZCG8Rldbqs85Hpng71Xdyc1UK5f5xwkt8eykasw9T5RbNYmQdlLjOd6C6N6/+jTV7rjzz6l2eMxth/3RH9xC56xOuVsJAcDRKW4PXnMFtxwDdV9a2y+4hs7Zvfc+qsXauHX1o0deoFr3Ne7stlzgzg4EgIFJbr9qlVuiU/zSgQivJ9e5qsc5vr2Xn98ssV8TkQE6Z85gV9UnABqJ755rvmEYZwf2F3SG4QkW7IbhCRbshuEJFuyG4QkW7IbhCS0tOBmXAOvj7mydV47xTK6x+knn+M1Xf4LOqVR4RlbjTweYyC2SIOY+Zn56yDkOAD39PGssNcvfa/c8fT/V7v4vH6baX//tj53jf/f4I3TOx26/g2rf3v0E1Xa++w+oFku6exq9Y4u74CgA/OtzvAhkQOxXALj6Xe+lWm/KbWuNHf85nTM6xe212Vl+nZZDbLlYvkC1jSvdf2zWE+N/ga6d7jmRIOT6pYphGG8rLNgNwxMs2A3DEyzYDcMTLNgNwxMs2A3DE1pqvdUgmKq7s5e2rl1N5/3g1687x/s6Fr84TirF7ZOjI+7sqkDzdE5ReW+wyTFenzMa4e/Do0PPUO1z97rtyC/f97/pnE/897+k2h/d8QGqqfBMtErNXcQyEfD+fNu38mtgsMhrIUSFW3a9q92ZYztWraFzkONW6tNP8NS28klu93YJzyyUrPsaKWezdA5rAycht2+7sxuGJ1iwG4YnWLAbhidYsBuGJ1iwG4YntHQ3PhoAfW3u95cgwVs5dWfc9cLKVd7SqBZSFy6u/D0ulubrmJ0adx+vje+0phPTVJtN8nXUirxOXr7Od333Pfl15/hFG/jxgnUlql20iSdwtCUzVEPdnTCSSvKElpNRXj9tOOS+dLLK21dtn3RfO0EPd1A2Zfh1Nb2FShiu82tua/s2qq1pdydmDef20zmq7uu0Br4Gu7MbhidYsBuGJ1iwG4YnWLAbhidYsBuGJ1iwG4YnzGm9ich6AP+MRktmBbBLVb8kIp8F8FEApwrEfUpVeaEzAOlYApevc7dl+sWew3TehStI+6eQFj41kogBADXlyQy5whjVQCy7eLSDTunu4skdUyePUy07E1KPLcaTSTSYcY6n6rzu3qUX81ZZhVxIzbWA3yuipP1TtcLPfVDh9dPiIa+5LNxWfG5mxDm+coyfj/Z23rKrXuQhU4u4zz0AFIRbsOWo+3UPTvJr8Ti5dHIFfi7m47NXAdypqs+ISAeAp0Vkd1P7oqr+9TyOYRjGMjOfXm9DAIaaj2dE5CCAtUu9MMMwFpe39JldRDYCuBTAk82hj4vIPhG5X0S6F3txhmEsHvMOdhFpB/AQgE+q6jSALwPYDOASNO78XyDzdorIXhHZO5nlnycMw1ha5hXsIhJDI9C/pqrfBQBVHVHVmqrWAXwFwJWuuaq6S1V3qOqO7gyvNmIYxtIyZ7BLo33KfQAOquq9p433n/ZtHwTA/2rfMIxlZz678dcA+AiAF0TkuebYpwB8SEQuQcOOOwrgj+c6UKVaxeiou5XTDasup/M617hb+AyWeYaPlrktp1FeO21maopqpZI7O2xFzzo6Z6rCM8rau1bw5ypkqVYu87p29ar7/bt/7Uo6p6LcampLn8OfKyTLS8Rtsalyy+v6DddRbWKSn8cTs9zOOzZwyDl+5fpNdE4tn6FaMfca1SIZno34WvZZqnXG3dZnddpdPw8ACkPubMR6hZ/f+ezGPwHAdYRQT90wjLML+ws6w/AEC3bD8AQLdsPwBAt2w/AEC3bD8ISWFpyczlfx6DOjTu0PL95K53V2XOgcf30ixF6rcVuoJjwjrlLh9omSbLlcnmc7xaK8gGUinqFaewfXirP8+Rht7dzG0UiCatEYX39MeCZapeq2yrjpCTyz331tAMB0hduN+UFuy2VK7ku8GOPXzkyMZ/qd089f88m82yIGgJERvsZaPeMcL1bdGXsAEEu5f2YScOvN7uyG4QkW7IbhCRbshuEJFuyG4QkW7IbhCRbshuEJLbXeKvU6RvLubJ09x1+i865a5c4KSre5LTkAiMd57nyYvRaEFFFMJNx2x8zMJJ3TEee2ViLG7bC2BO8fF1VemJGtP5HizxWJ8t5m+Rw/V6kObmF2pN2XVlgh0Gd/+TrVKj08s21lZg3V+jrcr/vICO9hlw+OUK1zLbci+9svotp44SjVRqZzzvHRGW43siKVipCCnlQxDONthQW7YXiCBbtheIIFu2F4ggW7YXiCBbtheEJLrTfU66iV3ZbHr187Sqe9PvyYc/zDH76Wzpku8l5pUG7LVQs8O6kt4c7Zqla4dVUsum0VAKiH9KpLpXn/OKTTVCrNuJ8vHudrjAg/H/UIzx6sOksTNucxh63Gz++6nsuodqLsLhwJAJ2beVHMNRG3NjvA7bVS2V0UFQBGR3nvgxUpfs31dHOr76l97sZtAb90cN4l7iKh8ViILcsPZxjG2wkLdsPwBAt2w/AEC3bD8AQLdsPwhDl340WkDcDjABLN7/+Oqn5GRM4F8E0AvQCeBvARVQ1v0xoVREhzx1qUJ4zkKu5d63xhms4phrRPSiUzVCsUef2xurrfG7s6ee2xfEiLpLYYbxuV6eNadnqQaiW4d2k72vkakwmupdp4i6qw9k8s2Sga5Ykw52+7hGonjg1QrVzg68gn3bvgIxGeZDI2xS/jzgJ3LrIhtevQxhOK6pJ1Hy/H23IdHRl2jperIUleVPk3SgBuVNV3otGe+X0ichWAzwH4oqpuATAJ4I55HMswjGVizmDXBqfesmLNfwrgRgDfaY4/AOCWpVigYRiLw3z7s0eaHVxHAewG8BqArKqe+v16AMDaJVmhYRiLwryCXVVrqnoJgHUArgTAq0a8CRHZKSJ7RWRvKcc/WxmGsbS8pd14Vc0C+BmAqwFkROTUBt86AM5dI1Xdpao7VHVHIm2b/4axXMwZfSLSJyKZ5uMkgPcAOIhG0P9e89tuB/CDJVqjYRiLwHwSYfoBPCAiETTeHB5U1R+KyAEA3xSRvwDwLID75jxSIEDanUxSSnBLo5fUGBPSjgkASvkpruXyVCtWuO0Sjbhb/8Rj/DSGtX+azg5RLRJiawXCj9mTcddc0whPWomGtH+qK09cqdTGqQbwmneMOHeakA3cVhMAxEZ5AsqeLvdrO1rgyS6bciupNlHj19XQBD9mX4ZbmB3tGed4dpL/zEbG3OOVasjPmSpNVHUfgEsd44fR+PxuGMZvAPYh2jA8wYLdMDzBgt0wPMGC3TA8wYLdMDxBNMS+WvQnEzkJ4FjzyxUAiIHQUmwdb8TW8UZ+09axQVX7XEJLg/0NTyyyV1V3LMuT2zpsHR6uw36NNwxPsGA3DE9YzmDftYzPfTq2jjdi63gjb5t1LNtndsMwWov9Gm8YnrAswS4i7xORl0XkVRG5aznW0FzHURF5QUSeE5G9LXze+0VkVET2nzbWIyK7ReRQ8//uZVrHZ0VksHlOnhORm1qwjvUi8jMROSAiL4rIJ5rjLT0nIeto6TkRkTYR2SMizzfX8efN8XNF5Mlm3HxLJKRvlwtVbek/ABE0ylptAhAH8DyAba1eR3MtRwGsWIbnvQ7AZQD2nzb2eQB3NR/fBeBzy7SOzwL4ry0+H/0ALms+7gDwCoBtrT4nIeto6TkBIADam49jAJ4EcBWABwHc1hz/RwB/8laOuxx39isBvKqqh7VRevqbAG5ehnUsG6r6OIA3J2HfjEbhTqBFBTzJOlqOqg6p6jPNxzNoFEdZixafk5B1tBRtsOhFXpcj2NcCOL1t5XIWq1QAj4rI0yKyc5nWcIpVqnqqmsUwgFXLuJaPi8i+5q/5S/5x4nREZCMa9ROexDKekzetA2jxOVmKIq++b9Bdq6qXAXg/gI+JyHXLvSCg8c6OxhvRcvBlAJvR6BEwBOALrXpiEWkH8BCAT6rqGzqAtPKcONbR8nOiCyjyyliOYB8EsP60r2mxyqVGVQeb/48C+B6Wt/LOiIj0A0Dz/9HlWISqjjQvtDqAr6BF50REYmgE2NdU9bvN4ZafE9c6luucNJ87i7dY5JWxHMH+FIDzmjuLcQC3AXi41YsQkbSIdJx6DOC9APaHz1pSHkajcCewjAU8TwVXkw+iBedERASNGoYHVfXe06SWnhO2jlafkyUr8tqqHcY37TbehMZO52sA/tsyrWETGk7A8wBebOU6AHwDjV8HK2h89roDjZ55jwE4BOCnAHqWaR3/E8ALAPahEWz9LVjHtWj8ir4PwHPNfze1+pyErKOl5wTAxWgUcd2HxhvLp0+7ZvcAeBXAtwEk3spx7S/oDMMTfN+gMwxvsGA3DE+wYDcMT7BgNwxPsGA3DE+wYDcMT7BgNwxPsGA3DE/4vzqmmmdY7AUFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load an image file to test\n",
    "\n",
    "img= image.load_img(\"dog.jpg\", target_size=(32,32))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac4949a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a numpy array\n",
    "\n",
    "image_to_test= image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f07e6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fourth dimension to the image, since Keras expects a list of images, not a single image\n",
    "\n",
    "list_of_images= np.expand_dims(image_to_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b0e0c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using the model\n",
    "\n",
    "results= model.predict(list_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00ab5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are only testing one image, we only need to check the first result\n",
    "\n",
    "single_result= results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "31d2287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will get a likelihood score for all 10 possible classes. Find out which class has the highest score\n",
    "\n",
    "most_likely_class_index= int(np.argmax(single_result))\n",
    "class_likelihood= single_result[most_likely_class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a09dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of the most likely class\n",
    "class_label= class_labels[most_likely_class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f21fa9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is image is a Dog- Likelihood: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#Print the result\n",
    "\n",
    "print(\"This is image is a {}- Likelihood: {:2f}\".format(class_label, class_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f6109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6544b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
